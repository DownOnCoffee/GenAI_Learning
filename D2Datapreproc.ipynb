{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP2H1Zx0OolDeUoVUNgTyPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DownOnCoffee/GenAI_Learning/blob/main/D2Datapreproc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2DTLU5ijPna9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/IMDB Dataset.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kUlDEybQYXN",
        "outputId": "c5b2ccfb-6163-4f89-b147-c0bcbe9b931b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearing html tags"
      ],
      "metadata": {
        "id": "gSbVi9UmeA1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>') #Every substring in text that matches the pattern is replaced with an empty string ''.\n",
        "    return pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "586GcWJfeD3J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_html_tags)"
      ],
      "metadata": {
        "id": "-RuOiulPepiw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['review'][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ePrbYSe52e",
        "outputId": "d86acf98-4f87-46a2-d144-82cd27adf719"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercase"
      ],
      "metadata": {
        "id": "S6LhjWLje-GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']=df['review'].str.lower()"
      ],
      "metadata": {
        "id": "4NHiHI29e_mP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove puntuations"
      ],
      "metadata": {
        "id": "e6DCLFn9fOsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "puncs_chars = string.punctuation"
      ],
      "metadata": {
        "id": "91jzTf67fQam"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_puncs(text):\n",
        "  for char in puncs_chars:\n",
        "    text = text.replace(char, '')\n",
        "  return text"
      ],
      "metadata": {
        "id": "dG310V-pf2_4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = 'A, string !! with puncs ...'\n",
        "print(remove_puncs(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA_42qzhgiJd",
        "outputId": "95cebc8d-6607-4569-cd68-f19bbd8e67e8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A string  with puncs \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']=df['review'].apply(remove_puncs)"
      ],
      "metadata": {
        "id": "CPw6XIR4h29I"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "handling spelling mistake"
      ],
      "metadata": {
        "id": "5eZbiNjowUeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "phznenSWwW4l"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'manhya likes studyding mathemattics !'\n",
        "corrected = TextBlob(text)\n",
        "corrected.correct().string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wLPeSs9wwnKX",
        "outputId": "3ab6359b-35c7-47d9-892f-bdf01077fa67"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'many likes studying mathematics !'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling emojis"
      ],
      "metadata": {
        "id": "MYBbUgZtynIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp6yosi7ypFQ",
        "outputId": "46183655-76ff-4f46-94c5-4af2623a3a3a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/608.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m307.2/608.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "print(emoji.demojize('I love this course üòò'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrvEyR59zLH_",
        "outputId": "59f01fdf-46e7-4f7b-edb5-362074f52afd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love this course :face_blowing_a_kiss:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization using split and nltk"
      ],
      "metadata": {
        "id": "J6GFa5u-0QQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1sWUNdc0WCk",
        "outputId": "02f53159-3340-42af-da8c-68f1cc132f69"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
        "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
        "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
        "\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "id": "qhKVNIkZ0mIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "zMW7fvbf3Bq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = df['review'][2]\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "for word in sentence_words:\n",
        "  if (word != wordnet_lemmatizer.lemmatize(word)):\n",
        "      print (word,wordnet_lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "Z5iW2vCn3Ceo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}