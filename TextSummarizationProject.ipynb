{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMb0XkjkcpgS6giX7HgzBj7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DownOnCoffee/GenAI_Learning/blob/main/TextSummarizationProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU4kawvDRuQb"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
      ],
      "metadata": {
        "id": "wneexDQ7Uhys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "zkRpN1s_Upgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate"
      ],
      "metadata": {
        "id": "0ehj8TcRVAPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "# rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "vuUkWSRSUtXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "Q6Md-UM2WsoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "dr64LpfBXRa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"google/pegasus-cnn_dailymail\"\n",
        "InferenceModel =  AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device) #Loads the model and shifts it to CPU/GPU"
      ],
      "metadata": {
        "id": "C9trvOgNXZQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "QheJoqr_fhLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"neil-code/dialogsum-test\")"
      ],
      "metadata": {
        "id": "k--wq64vf2hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "WoaBPYYJg1aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_length = This sets the maximum number of tokens allowed.\n",
        "\n",
        "If the dialogue is shorter than 1024 tokens → nothing special happens\n",
        "\n",
        "If it is longer than 1024 tokens → extra tokens are cut off\n",
        "\n",
        "truncation = If the text is longer than max_length, truncate it instead of throwing an error\n",
        "\n",
        "-----------\n",
        "\n",
        "\"labels\" is a special, reserved key in Hugging Face Transformers.\n",
        "It tells the model:\n",
        "These are the correct answers the model should learn to predict"
      ],
      "metadata": {
        "id": "74Q5vDHKoK15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data_func(data):\n",
        "  input_encodings = tokenizer(data['dialogue'] ,max_length = 1024, truncation = True)\n",
        "  output_encodings =  tokenizer(data['summary'] ,max_length = 1024, truncation = True)\n",
        "  return {\n",
        "      'input_ids': input_encodings['input_ids'],\n",
        "      'labels': output_encodings['input_ids'],\n",
        "      'attention_masks': input_encodings['attention_mask']\n",
        "  }\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_data_func, batched= True)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "_fUeD7eKhJLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'][8]"
      ],
      "metadata": {
        "id": "yOhidRc5ylvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_name)"
      ],
      "metadata": {
        "id": "xyKir6GQ0Vy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-neilcode', num_train_epochs=1, warmup_steps=500,\n",
        "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    eval_strategy=\"steps\", # eval_strategy is to check after how many N steps should the model stop training and test/evaluate the model and then resume\n",
        "    gradient_accumulation_steps=16,\n",
        ")"
      ],
      "metadata": {
        "id": "9-z55fWJztRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model = Trainer(model=InferenceModel, tokenizer=tokenizer, args=trainer_args,train_dataset = tokenized_dataset['test'],eval_dataset=tokenized_dataset['validation'], data_collator=seq2seq_data_collator )\n"
      ],
      "metadata": {
        "id": "_dIeEsGpAjDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model.train()"
      ],
      "metadata": {
        "id": "Len8ROzaLB4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=train_model.evaluate()"
      ],
      "metadata": {
        "id": "hFjQL1L_kNA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model evaluation :', res)"
      ],
      "metadata": {
        "id": "9C7zXSpvpWh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InferenceModel.save_pretrained(\"pegasus-dailymodel\")"
      ],
      "metadata": {
        "id": "0C236aJGsgrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "input_text = tokenized_dataset['test'][20]['dialogue']\n",
        "input_expected_summary = tokenized_dataset['test'][20]['summary']\n",
        "\n",
        "print('Input dialogue: ', input_text)\n",
        "print('Expected Summary: ',input_expected_summary)\n",
        "\n",
        "test_finetuned_model = pipeline(\"summarization\",model=\"pegasus-dailymodel\",tokenizer=tokenizer)\n",
        "\n",
        "answer = test_finetuned_model(input_text)\n",
        "\n",
        "print('Answer: ',answer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uyK6aWbhq0EQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}